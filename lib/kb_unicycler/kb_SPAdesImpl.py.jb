# -*- coding: utf-8 -*-
#BEGIN_HEADER
# The header block is where all import statements should live
from __future__ import print_function
import os
import re
import uuid
import requests
import json
import psutil
import subprocess
import numpy as np
import yaml
import time

from installed_clients.WorkspaceClient import Workspace
from installed_clients.ReadsUtilsClient import ReadsUtils  # @IgnorePep8
from installed_clients.baseclient import ServerError
from installed_clients.AssemblyUtilClient import AssemblyUtil
from installed_clients.KBaseReportClient import KBaseReport
from installed_clients.kb_quastClient import kb_quast
from installed_clients.kb_ea_utilsClient import kb_ea_utils

from kb_SPAdes.utils.spades_assembler import SPAdesAssembler


class ShockException(Exception):
    pass

#END_HEADER


class kb_SPAdes:
    '''
    Module Name:
    kb_SPAdes

    Module Description:
    A KBase module: gaprice_SPAdes
Simple wrapper for the SPAdes assembler.
http://bioinf.spbau.ru/spades

Always runs in careful mode.
Runs 3 threads / CPU.
Maximum memory use is set to available memory - 1G.
Autodetection is used for the PHRED quality offset and k-mer sizes.
A coverage cutoff is not specified.
    '''

    ######## WARNING FOR GEVENT USERS ####### noqa
    # Since asynchronous IO can lead to methods - even the same method -
    # interrupting each other, you must be *very* careful when using global
    # state. A method could easily clobber the state set by another while
    # the latter method is running.
    ######################################### noqa
    VERSION = "0.0.3"
    GIT_URL = "https://github.com/jkbaumohl/kb_SPAdes"
    GIT_COMMIT_HASH = "614a888d44b21561ac18519d15bf6db65c0cc4c2"

    #BEGIN_CLASS_HEADER
    # Class variables and functions can be defined in this block
    DISABLE_SPADES_OUTPUT = False  # should be False in production

    PARAM_IN_WS = 'workspace_name'
    PARAM_IN_LIB = 'read_libraries'
    PARAM_IN_CS_NAME = 'output_contigset_name'
    PARAM_IN_DNA_SOURCE = 'dna_source'
    PARAM_IN_SINGLE_CELL = 'single_cell'
    PARAM_IN_METAGENOME = 'metagenome'

    INVALID_WS_OBJ_NAME_RE = re.compile('[^\\w\\|._-]')
    INVALID_WS_NAME_RE = re.compile('[^\\w:._-]')

    THREADS_PER_CORE = 3
    MEMORY_OFFSET_GB = 1  # 1GB
    MIN_MEMORY_GB = 5
    GB = 1000000000

    URL_WS = 'workspace-url'
    URL_SHOCK = 'shock-url'
    URL_KB_END = 'kbase-endpoint'

    TRUE = 'true'
    FALSE = 'false'

    def log(self, message, prefix_newline=False):
        print(('\n' if prefix_newline else '') +
              str(time.time()) + ': ' + str(message))

    def check_shock_response(self, response, errtxt):
        if not response.ok:
            try:
                err = json.loads(response.content)['error'][0]
            except:
                # this means shock is down or not responding.
                self.log("Couldn't parse response error content from Shock: " +
                         response.content)
                response.raise_for_status()
            raise ShockException(errtxt + str(err))

    # Helper script borrowed from the transform service, logger removed
    def upload_file_to_shock(self, file_path, token):
        """
        Use HTTP multi-part POST to save a file to a SHOCK instance.
        """

        if token is None:
            raise Exception("Authentication token required!")

        header = {'Authorization': "Oauth {0}".format(token)}

        if file_path is None:
            raise Exception("No file given for upload to SHOCK!")

        with open(os.path.abspath(file_path), 'rb') as data_file:
            files = {'upload': data_file}
            response = requests.post(
                self.shockURL + '/node', headers=header, files=files,
                stream=True, allow_redirects=True)
        self.check_shock_response(
            response, ('Error trying to upload contig FASTA file {} to Shock: '
                       ).format(file_path))
        return response.json()['data']

    def generate_spades_yaml(self, reads_data):
        left = []  # fwd in fr orientation
        right = []  # rev
        interlaced = []
        for read in reads_data:
            if 'rev_file' in read and read['rev_file']:
                left.append(read['fwd_file'])
                right.append(read['rev_file'])
            else:
                interlaced.append(read['fwd_file'])
        yml = [{'type': 'paired-end',
                'orientation': 'fr'}]
        if left:
            yml[0]['left reads'] = left
            yml[0]['right reads'] = right
        if interlaced:
            yml[0]['interlaced reads'] = interlaced
        yml_path = os.path.join(self.scratch, 'run.yaml')
        with open(yml_path, 'w') as yml_file:
            yaml.safe_dump(yml, yml_file)
        return yml_path

    def exec_spades(self, dna_source, reads_data, phred_type):
        threads = psutil.cpu_count() * self.THREADS_PER_CORE
        mem = (psutil.virtual_memory().available / self.GB -
               self.MEMORY_OFFSET_GB)
        if mem < self.MIN_MEMORY_GB:
            raise ValueError(
                'Only ' + str(psutil.virtual_memory().available) +
                ' bytes of memory are available. The SPAdes wrapper will' +
                ' not run without at least ' +
                str(self.MIN_MEMORY_GB + self.MEMORY_OFFSET_GB) +
                ' gigabytes available')

        outdir = os.path.join(self.scratch, 'spades_output_dir')
        if not os.path.exists(outdir):
            os.makedirs(outdir)
        tmpdir = os.path.join(self.scratch, 'spades_tmp_dir')
        if not os.path.exists(tmpdir):
            os.makedirs(tmpdir)

        cmd = ['spades.py', '--threads', str(threads),
               '--memory', str(mem), '-o', outdir, '--tmp-dir', tmpdir]
        if dna_source == self.PARAM_IN_SINGLE_CELL:
            cmd += ['--sc']
        if dna_source == self.PARAM_IN_METAGENOME:
            cmd += ['--meta']
        else:
            cmd += ['--careful']
        cmd += ['--phred-offset', phred_type]
#        print("LENGTH OF READSDATA IN EXEC: " + str(len(reads_data)))
        print("SPADES YAML: " + str(self.generate_spades_yaml(reads_data)))
        cmd += ['--dataset', self.generate_spades_yaml(reads_data)]
        self.log('Running SPAdes command line:')
#        print("SPADES CMD:" + str(cmd))
        self.log(cmd)

        if self.DISABLE_SPADES_OUTPUT:
            with open(os.devnull, 'w') as null:
                p = subprocess.Popen(cmd, cwd=self.scratch, shell=False,
                                     stdout=null)
        else:
            p = subprocess.Popen(cmd, cwd=self.scratch, shell=False)
        retcode = p.wait()

        self.log('Return code: ' + str(retcode))
        if p.returncode != 0:
            raise ValueError('Error running SPAdes, return code: ' +
                             str(retcode) + '\n')

        return outdir

    # adapted from
    # https://github.com/kbase/transform/blob/master/plugins/scripts/convert/trns_transform_KBaseFile_AssemblyFile_to_KBaseGenomes_ContigSet.py
    # which was adapted from an early version of
    # https://github.com/kbase/transform/blob/master/plugins/scripts/upload/trns_transform_FASTA_DNA_Assembly_to_KBaseGenomes_ContigSet.py
    def load_stats(self, input_file_name):
        self.log('Starting conversion of FASTA to KBaseGenomeAnnotations.Assembly')
        self.log('Building Object.')
        if not os.path.isfile(input_file_name):
            raise Exception('The input file name {0} is not a file!'.format(
                input_file_name))
        with open(input_file_name, 'r') as input_file_handle:
            contig_id = None
            sequence_len = 0
            fasta_dict = dict()
            first_header_found = False
            # Pattern for replacing white space
            pattern = re.compile(r'\s+')
            for current_line in input_file_handle:
                if (current_line[0] == '>'):
                    # found a header line
                    # Wrap up previous fasta sequence
                    if not first_header_found:
                        first_header_found = True
                    else:
                        fasta_dict[contig_id] = sequence_len
                        sequence_len = 0
                    fasta_header = current_line.replace('>', '').strip()
                    try:
                        contig_id = fasta_header.strip().split(' ', 1)[0]
                    except:
                        contig_id = fasta_header.strip()
                else:
                    sequence_len += len(re.sub(pattern, '', current_line))
        # wrap up last fasta sequence, should really make this a method
        if not first_header_found:
            raise Exception("There are no contigs in this file")
        else:
            fasta_dict[contig_id] = sequence_len
        return fasta_dict

    def load_report(self, input_file_name, params, wsname):
        fasta_stats = self.load_stats(input_file_name)
        lengths = [fasta_stats[contig_id] for contig_id in fasta_stats]

        assembly_ref = params[self.PARAM_IN_WS] + '/' + params[self.PARAM_IN_CS_NAME]

        report = ''
        report += 'Assembly saved to: ' + assembly_ref + '\n'
        report += 'Assembled into ' + str(len(lengths)) + ' contigs.\n'
        report += 'Avg Length: ' + str(sum(lengths) / float(len(lengths))) + \
            ' bp.\n'

        # compute a simple contig length distribution
        bins = 10
        counts, edges = np.histogram(lengths, bins)  # @UndefinedVariable
        report += 'Contig Length Distribution (# of contigs -- min to max ' +\
            'basepairs):\n'
        for c in range(bins):
            report += '   ' + str(counts[c]) + '\t--\t' + str(edges[c]) +\
                ' to ' + str(edges[c + 1]) + ' bp\n'
        report_cl = KBaseReport(self.callbackURL, service_ver='dev')
        reportObj = {
            'objects_created': [{'ref': assembly_ref,
                                 'description': 'Assembled contigs'}],
            'text_message': report
        }
        report_info = report_cl.create({'report': reportObj,
                                        'workspace_name': wsname})
        reportName = report_info['name']
        reportRef = report_info['ref']
        return reportName, reportRef

    def make_ref(self, object_info):
        return str(object_info[6]) + '/' + str(object_info[0]) + \
            '/' + str(object_info[4])

    def check_reads(self, params, reads, reftoname):

        phred64_reads = set()
        phred33_reads = set()
        unknown_phred_reads = set()

        print("BEFORE READ CHECK LOOPING")

        for ref in reads:
            rds = reads[ref]
            obj_name = reftoname[ref]
            obj_ref = rds['ref']

            if rds['phred_type'] == 33:
                phred33_reads.add(obj_name)
            elif rds['phred_type'] == 64:
                phred64_reads.add(obj_name)
            else:
                unknown_phred_reads.add(ref)

            print("READ PHRED33:"+str(len(phred33_reads)))
            print("READ PHRED64:"+str(len(phred64_reads)))
            print("READ UNKNOWN:"+str(len(unknown_phred_reads)))

            if rds['read_orientation_outward'] == self.TRUE:
                raise ValueError(
                    ('Reads object {} ({}) is marked as having outward ' +
                     'oriented reads, which SPAdes does not ' +
                     'support.').format(obj_name, obj_ref))

            # ideally types would be firm enough that we could rely on the
            # metagenomic boolean. However KBaseAssembly doesn't have the field
            # and it's optional anyway. Ideally fix those issues and then set
            # the --meta command line flag automatically based on the type
            if (rds['single_genome'] == self.TRUE and
                    params[self.PARAM_IN_DNA_SOURCE] ==
                    self.PARAM_IN_METAGENOME):
                raise ValueError(
                    ('Reads object {} ({}) is marked as containing dna from ' +
                     'a single genome but the assembly method was specified ' +
                     'as metagenomic').format(obj_name, obj_ref))
            if (rds['single_genome'] == self.FALSE and
                    params[self.PARAM_IN_DNA_SOURCE] !=
                    self.PARAM_IN_METAGENOME):
                raise ValueError(
                    ('Reads object {} ({}) is marked as containing ' +
                     'metagenomic data but the assembly method was not ' +
                     'specified as metagenomic').format(obj_name, obj_ref))

        print("BEFORE CHECKING")
        # CHECK TO SEE IF ALL READS CONSISTENT IN PHRED Type
        # IF UNKNOWN TYPE NEED TO DETERMINE PHRED TYPE USING EAUTILS
        if len(unknown_phred_reads) > 0:
            print("IN UNKNOWN CHECKING")
            eautils = kb_ea_utils(self.callbackURL)
            for ref in unknown_phred_reads:
                rds = reads[ref]
                obj_name = reftoname[ref]
                files_to_check = []
                f = rds['files']
                if f['type'] == 'interleaved':
                    files_to_check.append(f['fwd'])
                elif f['type'] == 'paired':
                    files_to_check.append(f['fwd'])
                    files_to_check.append(f['rev'])
                print("FILES TO CHECK:" + str(files_to_check))
                for file_path in files_to_check:
                    ea_stats_dict = eautils.calculate_fastq_stats({'read_library_path': file_path})
                    print("EA UTILS STATS : " + str(ea_stats_dict))
                    if ea_stats_dict['phred_type'] == '33':
                        phred33_reads.add(obj_name)
                        print("IN 33 ADD")
                    elif ea_stats_dict['phred_type'] == '64':
                        phred64_reads.add(obj_name)
                        print("IN 64 ADD")
                    print("FILE {} PHRED {}".format(file_path, ea_stats_dict['phred_type']))

        print("ROUND2:")
        print("READ PHRED33:"+str(len(phred33_reads)))
        print("READ PHRED64:"+str(len(phred64_reads)))
        print("READ UNKNOWN:"+str(len(unknown_phred_reads)))

        # IF THERE ARE READS OF BOTH PHRED 33 and 64, throw an error
        if (len(phred64_reads) > 0) and (len(phred33_reads) > 0):
            raise ValueError(
                    ('The set of Reads objects passed in have reads that have different ' +
                     'phred type scores. SPAdes does not support assemblies of ' +
                     'reads with different phred type scores.\nThe following read objects ' +
                     'have phred 33 scores : {}.\nThe following read objects have phred 64 ' +
                     'scores : {}').format(", ".join(phred33_reads),", ".join(phred64_reads)))
        elif len(phred64_reads) > 0:
            return '64'
        elif len(phred33_reads) > 0:
            return '33'
        print("AFTER CHECKING")

    def process_params(self, params):
        if (self.PARAM_IN_WS not in params or
                not params[self.PARAM_IN_WS]):
            raise ValueError(self.PARAM_IN_WS + ' parameter is required')
        if self.INVALID_WS_NAME_RE.search(params[self.PARAM_IN_WS]):
            raise ValueError('Invalid workspace name ' +
                             params[self.PARAM_IN_WS])
        if self.PARAM_IN_LIB not in params:
            raise ValueError(self.PARAM_IN_LIB + ' parameter is required')
        if type(params[self.PARAM_IN_LIB]) != list:
            raise ValueError(self.PARAM_IN_LIB + ' must be a list')
        if not params[self.PARAM_IN_LIB]:
            raise ValueError('At least one reads library must be provided')
        for l in params[self.PARAM_IN_LIB]:
            if self.INVALID_WS_OBJ_NAME_RE.search(l):
                raise ValueError('Invalid workspace object name ' + l)
        if (self.PARAM_IN_CS_NAME not in params or
                not params[self.PARAM_IN_CS_NAME]):
            raise ValueError(self.PARAM_IN_CS_NAME + ' parameter is required')
        if self.INVALID_WS_OBJ_NAME_RE.search(params[self.PARAM_IN_CS_NAME]):
            raise ValueError('Invalid workspace object name ' +
                             params[self.PARAM_IN_CS_NAME])
        if self.PARAM_IN_DNA_SOURCE in params:
            s = params[self.PARAM_IN_DNA_SOURCE]
            if s not in [self.PARAM_IN_SINGLE_CELL, self.PARAM_IN_METAGENOME]:
                params[self.PARAM_IN_DNA_SOURCE] = None
        else:
            params[self.PARAM_IN_DNA_SOURCE] = None

    #END_CLASS_HEADER

    # config contains contents of config file in a hash or None if it couldn't
    # be found
    def __init__(self, config):
        #BEGIN_CONSTRUCTOR
        self.callbackURL = os.environ['SDK_CALLBACK_URL']
        self.log('Callback URL: ' + self.callbackURL)
        self.workspaceURL = config[self.URL_WS]
        self.shockURL = config[self.URL_SHOCK]
        self.catalogURL = config[self.URL_KB_END] + '/catalog'
        self.scratch = os.path.abspath(config['scratch'])
        if not os.path.exists(self.scratch):
            os.makedirs(self.scratch)
        #END_CONSTRUCTOR
        pass

    def run_SPAdes(self, ctx, params):
        """
        Run SPAdes on paired end libraries
        :param params: instance of type "SPAdesParams" (Input parameters for
           running SPAdes. string workspace_name - the name of the workspace
           from which to take input and store output. string
           output_contigset_name - the name of the output contigset
           list<paired_end_lib> read_libraries - Illumina PairedEndLibrary
           files to assemble. string dna_source - the source of the DNA used
           for sequencing 'single_cell': DNA amplified from a single cell via
           MDA 'metagenome': Metagenomic data anything else: Standard DNA
           sample from multiple cells) -> structure: parameter
           "workspace_name" of String, parameter "output_contigset_name" of
           String, parameter "read_libraries" of list of type
           "paired_end_lib" (The workspace object name of a PairedEndLibrary
           file, whether of the KBaseAssembly or KBaseFile type.), parameter
           "dna_source" of String
        :returns: instance of type "SPAdesOutput" (Output parameters for
           SPAdes run. string report_name - the name of the
           KBaseReport.Report workspace object. string report_ref - the
           workspace reference of the report.) -> structure: parameter
           "report_name" of String, parameter "report_ref" of String
        """
        # ctx is the context object
        # return variables are: output
        #BEGIN run_SPAdes

        # A whole lot of this is adapted or outright copied from
        # https://github.com/msneddon/MEGAHIT
        self.log('Running run_SPAdes with params:\n' + pformat(params))

        token = ctx['token']

        # the reads should really be specified as a list of absolute ws refs
        # but the narrative doesn't do that yet
        self.process_params(params)

        # get absolute refs from ws
        wsname = params[self.PARAM_IN_WS]
        obj_ids = []
        for r in params[self.PARAM_IN_LIB]:
            obj_ids.append({'ref': wsname + '/' + r})
        ws = workspaceService(self.workspaceURL, token=token)
        ws_info = ws.get_object_info_new({'objects': obj_ids})
        reads_params = []
        reftoname = {}
        for wsi, oid in zip(ws_info, obj_ids):
            ref = self.make_ref(wsi)
            reads_params.append(ref)
            obj_name = oid['ref']
            reftoname[ref] = obj_name

        readcli = ReadsUtils(self.callbackURL, token=ctx['token'], service_ver='dev')

        typeerr = ('Supported types: KBaseFile.SingleEndLibrary ' +
                   'KBaseFile.PairedEndLibrary ' +
                   'KBaseAssembly.SingleEndLibrary ' +
                   'KBaseAssembly.PairedEndLibrary')
        try:
            reads = readcli.download_reads({'read_libraries': reads_params,
                                            'interleaved': 'false',
                                            'gzipped': None
                                            })['files']
        except ServerError as se:
            self.log('logging stacktrace from dynamic client error')
            self.log(se.data)
            if typeerr in se.message:
                prefix = se.message.split('.')[0]
                raise ValueError(
                    prefix + '. Only the types ' +
                    'KBaseAssembly.PairedEndLibrary ' +
                    'and KBaseFile.PairedEndLibrary are supported')
            else:
                raise

        self.log('Got reads data from converter:\n' + pformat(reads))

        phred_type = self.check_reads(params, reads, reftoname)

        reads_data = []
        for ref in reads:
            reads_name = reftoname[ref]
            f = reads[ref]['files']
            if f['type'] == 'single':
                raise ValueError(('{} is a single end read library, which ' +
                                  'is not currently supported.').format(reads_name))
            if f['type'] == 'interleaved':
                reads_data.append({'fwd_file': f['fwd']})
            elif f['type'] == 'paired':
                reads_data.append({'fwd_file': f['fwd'], 'rev_file': f['rev']})
            else:
                raise ValueError('Something is very wrong with read lib' + reads_name)
        spades_out = self.exec_spades(params[self.PARAM_IN_DNA_SOURCE],
                                      reads_data, phred_type)
        self.log('SPAdes output dir: ' + spades_out)

        # parse the output and save back to KBase
        output_contigs = os.path.join(spades_out, 'scaffolds.fasta')

        self.log('Uploading FASTA file to Assembly')
        assemblyUtil = AssemblyUtil(self.callbackURL, token=ctx['token'], service_ver='dev')
        assemblyUtil.save_assembly_from_fasta({'file': {'path': output_contigs},
                                               'workspace_name': wsname,
                                               'assembly_name': params[self.PARAM_IN_CS_NAME]
                                               })

        report_name, report_ref = self.load_report(output_contigs, params, wsname)

        output = {'report_name': report_name,
                  'report_ref': report_ref
                  }
        #END run_SPAdes

        # At some point might do deeper type checking...
        if not isinstance(output, dict):
            raise ValueError('Method run_SPAdes return value ' +
                             'output is not type dict as required.')
        # return the results
        return [output]

    def status(self, ctx):
        #BEGIN_STATUS
        returnVal = {'state': "OK",
                     'message': "",
                     'version': self.VERSION,
                     'git_url': self.GIT_URL,
                     'git_commit_hash': self.GIT_COMMIT_HASH}
        del ctx  # shut up pep8
        #END_STATUS
        return [returnVal]
